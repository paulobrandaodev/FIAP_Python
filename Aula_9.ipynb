{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predição de Sobreviventes no Acidente do Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sumarizando tudo que estudamos até agora, vamos criar um workflow de resolução de problemas de machine learning que pode ser replicável e adaptável para qualquer dataset sobre o qual pretendemos executar um algoritmo de machine learning. O Workflow consiste em seis passos:\n",
    "\n",
    "> Definição do problema\n",
    "\n",
    "> Aquisição de dados de treinamento e teste\n",
    "\n",
    "> Manipulação, preparo e limpeza dos dados\n",
    "\n",
    "> Análise, identificação de padrão e exploração dos dados\n",
    "\n",
    "> Modelagem, predição e resolução do problema\n",
    "\n",
    "> Visualização e apresentação da solução final\n",
    "\n",
    "Não é um workflow linear, visto que podemos explorar nossos dados usando visualização, ou mesmo podemos suprimir um ou outro passo ou até combinar alguns passos num só. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição do problema\n",
    "\n",
    "A partir de um conjunto de treino que lista se os passageiros sobreviveram ou não ao desastre do Titanic, é possível criar um modelo que determine num conjunto de teste que não possui informação de sobrevivência dos passegeiros se estes sobreviveram ou não?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "#importando bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aquisição de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('bases/train.csv')\n",
    "test_df = pd.read_csv('bases/test.csv')\n",
    "combine = [train_df, test_df] # quando for necessário aplicar operações em ambos os conjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                              Name     Sex   Age  SibSp  \\\n",
       "0          892       3                  Kelly, Mr. James    male  34.5      0   \n",
       "1          893       3  Wilkes, Mrs. James (Ellen Needs)  female  47.0      1   \n",
       "2          894       2         Myles, Mr. Thomas Francis    male  62.0      0   \n",
       "\n",
       "   Parch  Ticket    Fare Cabin Embarked  \n",
       "0      0  330911  7.8292   NaN        Q  \n",
       "1      0  363272  7.0000   NaN        S  \n",
       "2      0  240276  9.6875   NaN        Q  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()\n",
    "print()\n",
    "print('-'*40)\n",
    "print()\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algumas observações:\n",
    "\n",
    "> 1) Estamos lidando tanto com features numéricas quanto com features categóricas em ambos os conjuntos\n",
    "\n",
    "> 2) Existem valores faltantes tanto no conjunto de treino quando no conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>681</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>347082</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name   Sex  Ticket    Cabin Embarked\n",
       "count                       891   891     891      204      889\n",
       "unique                      891     2     681      147        3\n",
       "top     Braund, Mr. Owen Harris  male  347082  B96 B98        S\n",
       "freq                          1   577       7        4      644"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validando hipóteses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos verificar algumas hipóteses aqui:\n",
    "> 1) A classe do passageiro(a), seu sexo, se ele(a) possui irmãos(ãs)/conjuge ou se possui pais/filhos interfere em sua sobreviência?\n",
    "\n",
    "> 2) A faixa de idade interfere de alguma maneira na sobrevivência?\n",
    "\n",
    "> 3) Todas as features possuem relevância ao predizer se um determinado passageiro irá sobreviver ou não?\n",
    "\n",
    "> 4) O título de um passageiro(a) interfere em sua sobrevivência? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ToDo 1) Hipótese 1\n",
    "\n",
    "Crie uma função que receba três parâmetros: dataset, atributo1, atributo2 (este será sempre a coluna 'Survived'). Retorne um dataframe que mostre a proporção dos que sobreviveram para cada valor presente no atributo1. Considere 'Pclass', 'sex', 'SibSp' e 'Parch' como valores possíveis para o atributo1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0.742038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.188908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Survived\n",
       "Sex             \n",
       "female  0.742038\n",
       "male    0.188908"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dica: filtre os dois atributos (ds[[attr1, attr2]]) e depois agrupe por attr1 e depois tire a média (como attr1 é binário, \n",
    "#a média retorna a proporção)\n",
    "# Resposta\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "def defineSurvive(data, attr1, Survived):\n",
    "    result = data[[attr1, Survived]].groupby([attr1]).mean()\n",
    "    return result\n",
    "\n",
    "defineSurvive(train_df, 'Sex', 'Survived')\n",
    "# train_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ToDo 2) Hipótese 2\n",
    "\n",
    "Plote um histograma da variável idade para cada resultado possível da variável Survived "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<AxesSubplot:title={'center':'0'}>,\n",
       "       <AxesSubplot:title={'center':'1'}>], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Dica: olhe os parametros do método hist do Pandas\n",
    "# Resposta\n",
    "train_df.hist(column=\"Age\", by=\"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ToDo 3) Hipótese 3\n",
    "\n",
    "Julgue as features que estão presentes no dataset. Caso alguma não seja considerada para predizer a sobrevivência de um passageiro, elimine-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resposta\n",
    "train_df.drop(columns=['Ticket','Cabin'])\n",
    "test_df.drop(columns=['Ticket','Cabin'])\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ToDo 4) Hipótese 4\n",
    "Ao analisar a coluna Name, verificamos uma série de títulos associados ao nome de um passageiro(a). Esses são os títulos presentes na coluna Name: 'Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Mlle', 'Ms', 'Mme', 'Master', 'Miss', 'Mr', 'Mrs'.\n",
    "\n",
    "Use regex para extrair os títulos a partir da coluna Name (faça para cada dataset). Insira os valores numa nova coluna chamada Title. Use Pandas.crosstab para verificar quantos passageiros de cada sexo possuem cada um dos títulos. [pd.crosstab](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.crosstab.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\logonrmlocal\\AppData\\Local\\Temp\\ipykernel_9912\\3443879719.py:4: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  train_df[\"Tittle\"] = train_df[\"Name\"].str.extract(r\"(,.*[a-zA-Z]+\\.)\")[0].str.replace(', ', '').str.replace('.', '')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        Mr\n",
       "1       Mrs\n",
       "2      Miss\n",
       "3       Mrs\n",
       "4        Mr\n",
       "       ... \n",
       "886     Rev\n",
       "887    Miss\n",
       "888    Miss\n",
       "889      Mr\n",
       "890      Mr\n",
       "Name: Tittle, Length: 891, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dica use o método str.extract do pandas\n",
    "# Resposta\n",
    "\n",
    "train_df[\"Tittle\"] = train_df[\"Name\"].str.extract(r\"(,.*[a-zA-Z]+\\.)\")[0].str.replace(', ', '').str.replace('.', '')\n",
    "train_df[\"Tittle\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ToDo 5) Hipótese 4\n",
    "Para cada dataset, faça as seguintes substituições na coluna Title:\n",
    "\n",
    "> 'Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona' por 'Rare'\n",
    "\n",
    "> 'Mlle' por 'Miss'\n",
    "\n",
    "> 'Ms' por 'Miss'\n",
    "\n",
    "> 'Mme' por 'Mrs'\n",
    "\n",
    "Verifique a porcentagem de sobrevivência para cada grupo (título)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\logonrmlocal\\AppData\\Local\\Temp\\ipykernel_9912\\1032545299.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_df[\"Tittle\"] = train_df[\"Tittle\"].str.replace(x,'Rare')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Mr        517\n",
       "Miss      185\n",
       "Mrs       125\n",
       "Master     40\n",
       "Rare       24\n",
       "Name: Tittle, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dica: use replace para fazer as substituições e a mesma solução do ToDo 1 para encontrar a porcentagem\n",
    "# Resposta\n",
    "\n",
    "replaces = ['Lady', 'Countess','Capt', 'Major','Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona', 'Mrs Martin \\(Elizabeth L', 'the Rare']\n",
    "\n",
    "for x in replaces:\n",
    "    train_df[\"Tittle\"] = train_df[\"Tittle\"].str.replace(x,'Rare')\n",
    "\n",
    "train_df[\"Tittle\"] = train_df[\"Tittle\"].str.replace('Mlle','Miss')\n",
    "train_df[\"Tittle\"] = train_df[\"Tittle\"].str.replace('Ms','Miss')\n",
    "train_df[\"Tittle\"] = train_df[\"Tittle\"].str.replace('Mme','Mrs')\n",
    "\n",
    "train_df[\"Tittle\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ToDo 6) Hipótese 4\n",
    "Mapeie cada um dos título para um número: 'Mr':1, 'Miss':2, 'Mrs':3, 'Master':4, 'Rare':5. Faça a alteração nos dois datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [4.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dica: use o método map\n",
    "# Resposta\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "features_cat = train_df[['Tittle']]\n",
    "features_cat_1hot = encoder.fit_transform(features_cat)\n",
    "features_cat_1hot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ToDo 7)\n",
    "Agora podemos eliminar as colunas Name e PassengerId com segurança, já que não serão mais úteis para nossas análises. Elimine-as em ambos os datasets (se houver):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resposta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ToDo 8)\n",
    "Mapeie os valores da coluna Sex para números: 'female':0, 'male':1. Faça a alteração em ambos os datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dica: use o método map - mesma solução ToDo 6\n",
    "# Resposta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ToDo 9)\n",
    "\n",
    "Temos valores faltantes tanto em train_df quanto em test_df e isso ocorre em colunas diferentes. Assim, vamos ter que tratar cada caso de uma maneira:\n",
    "\n",
    "Em train_df:\n",
    "\n",
    "> preencha os valores faltantes da coluna Age com a mediana\n",
    "\n",
    "> preencha os valores faltantes da coluna Embarked com a moda\n",
    "\n",
    "Em test_df:\n",
    "\n",
    "> preencha os valores faltantes da coluna Age com a mediana\n",
    "\n",
    "> preencha os valores faltantes da coluna Fare com a mediana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando\n",
    "print(train_df.isnull().sum())\n",
    "print('-'*40)\n",
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ToDo 10\n",
    "Precisamos ajustar os valores das colunas Age e Fare para valores ordinais numéricos. O código abaixo usa pd.cut para determinar as classes numéricas. O mesmo ocorre ao executar o código subsequente, mas dessa vez estamos usando pd.qcut, visto que os valores são contínuos, o que exige a classificação por quartis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['AgeBand'] = pd.cut(train_df['Age'], 5)\n",
    "train_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\n",
    "train_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Para cada dataset, altere o valor das colunas Age e Fare, conforme exemplo abaixo:\n",
    "Age < 16 == 0\n",
    "16 > Age <= 32 == 1\n",
    "32 > Age <= 48 == 2\n",
    "48 > Age <= 64 == 3\n",
    "Age > 64 == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elimine as colunas AgeBand e FareBand depois de realizadas as operações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dica: utilize o método loc dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
    "# Resposta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ToDo 11)\n",
    "Mapeie os valores da coluna Embarked para números: 'S':0, 'C':1, 'Q':2. Faça a alteração em ambos os datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dica: use o método map - mesma solução ToDo 6\n",
    "# Resposta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ToDo 12)\n",
    "Crie uma nova coluna chamada FamilySize que será a soma de SibSp e Parch + 1(caso seja somente o(a) passageiro(a)). Depois, crie uma nova coluna chamada IsAlone, cujo valor será 0, se FamilySize for igual a 1, ou 1, caso contrário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dica: utilize loc\n",
    "# Resposta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elimine as colunas Parch, SibSp e FamilySize, pois não vamos utilizá-las mais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "test_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que fizemos todas as correções em nossos datasets, podemos ver como ficaram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando nosso algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(\"Survived\", axis=1)\n",
    "y_train = train_df[\"Survived\"]\n",
    "X_test  = test_df.drop(\"PassengerId\", axis=1).copy()\n",
    "X_train.shape, y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "Y_pred = logreg.predict(X_test)\n",
    "acc_log = round(logreg.score(X_train, Y_train) * 100, 2)\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando com novas amostras\n",
    "\n",
    "Informações do passageiro:\n",
    "> 1º classe: 1\n",
    "\n",
    "> Sexo feminimo: 1\n",
    "\n",
    "> Idade 25: 1\n",
    "\n",
    "> Fare: 3\n",
    "\n",
    "> Embarked: 0\n",
    "\n",
    "> Title: 2\n",
    "\n",
    "> isAlone: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.predict(np.array([[1,1,1,3,0,2,0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fiquem a vontade para testar com novas amostrar. ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
